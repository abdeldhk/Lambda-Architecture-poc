# âœˆï¸ Lambda Architecture PoC â€” Flight Event Analytics

Welcome to the official Proof of Concept (PoC) for a full-stack **Lambda Architecture** project built by [@abdeldhk](https://github.com/abdeldhk). This system processes flight event data in **real-time and batch**, leveraging a modern big data stack, containerized via Docker.

---

## ğŸ§± Architecture Overview

This PoC implements the classical Lambda Architecture model:

- **Ingestion Layer** â†’ Rust-based Kafka producer simulating flight events
- **Batch Layer** â†’ PySpark job processes historical data into analytics-ready formats
- **Speed Layer** â†’ Real-time aggregation with Kafka Streams, Flink, and Spark Streaming
- **Serving Layer** â†’ Rust REST API delivers fast access to metrics

---

## âš™ï¸ Stack Components

| Layer            | Technology                                                  |
|------------------|-------------------------------------------------------------|
| Ingestion        | Rust + Apache Kafka                                         |
| Batch Layer      | PySpark + Hive-compatible S3 (MinIO)                        |
| Speed Layer      | Kafka Streams (Java), Apache Flink (Java), Spark Streaming (PySpark) |
| Serving Layer    | Rust (Actix Web)                                            |
| Storage          | Cassandra, MinIO, Elasticsearch                             |
| Containerization | Docker + Docker Compose                                     |

---

## ğŸš€ Getting Started

### ğŸ³ 1. Start the Infrastructure
```bash
cd docker
docker compose up -d
```

### ğŸª„ 2. Create Kafka Topics
```bash
docker exec kafka bash /kafka/create-topics.sh
```

### ğŸ”Œ 3. (Optional) Register Kafka File Sink Connector
```bash
./docker/scripts/register-kafka-sink.sh
```

### âœˆï¸ 4. Generate Flight Event Samples
```bash
cargo run --bin generate_flights
```

### ğŸ“¤ 5. Start the Kafka Producer
```bash
cargo run --bin kafka-producer
```

### ğŸ“¦ 6. Run the Batch ETL Job (PySpark)
```bash
spark-submit batch-layer/etl-job.py
```

---

## ğŸŒ REST API (Serving Layer)

Start the Rust-based API server:
```bash
cd serving-layer/rest-api
cargo run
```

### Example Endpoints:
- `GET /health` â†’ Health check
- `GET /route-counts?origin=DXB&destination=ZRH` â†’ Returns flight count for route

---

## ğŸ“ Directory Overview

```
Lambda-Architecture-poc/
â”œâ”€â”€ config/                # Kafka and topic configs
â”œâ”€â”€ data/                  # Generated flight events
â”œâ”€â”€ docker/                # Docker setup (Kafka, Spark, etc.)
â”œâ”€â”€ ingestion/             # Rust-based Kafka producer
â”œâ”€â”€ batch-layer/           # PySpark ETL job
â”œâ”€â”€ speed-layer/           # Spark, Flink, and Kafka Streams jobs
â”œâ”€â”€ serving-layer/         # Rust Actix REST API
â”œâ”€â”€ architecture.md        # System design documentation
â””â”€â”€ README.md              # This file
```

---

## ğŸ› ï¸ Useful UIs

| Tool        | URL                     |
|-------------|--------------------------|
| Spark UI    | http://localhost:8080    |
| Kafka UI    | http://localhost:8082 *(if enabled)* |
| Kibana      | http://localhost:5601 *(optional)* |

---

## ğŸ“Œ Roadmap

- [ ] Query Cassandra or Elasticsearch from REST API
- [ ] Add windowed aggregations (e.g. per 5 minutes)
- [ ] Add Prometheus + Grafana
- [ ] Package each job as an independent service

---

## ğŸ§  License

MIT Â© [Abdelhamid Dahak](https://github.com/abdeldhk)